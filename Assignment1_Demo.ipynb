{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Demo\n",
    "\n",
    "The aim of this demo is to help you become familiar with some of the Python packages and methods that you'll be using in Assignment 1. This demo will also help reinforce some of the theory that you've learned in the Information Retrieval module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the work environment\n",
    "\n",
    "To build a working environment for this demo, please refer to the **Assignment 1 - Setting up your work environment** instructions available on Wattle. \n",
    "\n",
    "1. unzip elasticsearch-6.3.0.zip, then run the code below in a Terminal/Console window: \n",
    "\n",
    "    `./elasticsearch-6.3.0/bin/elasticsearch -d`\n",
    "    \n",
    "    which will run **Elasticsearch** in the background.\n",
    "    \n",
    "    To check that Elasticsearch is running correctly, open your browser and go to *http://localhost:9200*. If \n",
    "    ElasticSearch is working correctly, you will see something like the below in your browser:\n",
    "    \n",
    "    ![ElasticSearch](images/es_working.png)\n",
    "    \n",
    "1. To run the demo code, install the python Elasticsearch client via *pip*, with the code below: \n",
    "\n",
    "    `pip install elasticsearch`\n",
    "    \n",
    "1. To check that the client has installed correctly, run python and import the library: \n",
    "\n",
    "    `python -c \"import elasticsearch\"`\n",
    "    \n",
    "    If you don't receive any error messages, then your install has been successful.\n",
    "    \n",
    "1. You are now ready to proceed with the demo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 1: Indexing and Searching using ElasticSearch\n",
    "\n",
    "Now it's time to run some demo programs. \n",
    "\n",
    "In this demo, we will create an inverted index of six sample documents (indexing), and then use the Elasticsearch query grammar to search the documents (searching).\n",
    "\n",
    "To begin with, we'll first define some useful functions used for indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "#  A document class with following attributes:\n",
    "#   filename: document filename\n",
    "#   text: body of documment\n",
    "#   path: path of document\n",
    "\n",
    "Doc = namedtuple('Doc', 'filename path text')\n",
    "\n",
    "def read_doc(doc_path, encoding):\n",
    "    '''\n",
    "        reads a document from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - doc: instance of Doc namedtuple\n",
    "    '''\n",
    "    filename = doc_path.split('/')[-1]\n",
    "    fp = open(doc_path, 'r', encoding = encoding)\n",
    "    text = fp.read().strip()\n",
    "    fp.close()\n",
    "    return Doc(filename = filename, text = text, path = doc_path)\n",
    "\n",
    "def read_dataset(path, encoding = \"ISO-8859-1\"):\n",
    "    '''\n",
    "        reads multiple documents from path\n",
    "        input:\n",
    "            - doc_path : path of document\n",
    "            - encoding: encoding\n",
    "        output: =>\n",
    "            - docs: instances of Doc namedtuple returned as generator\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for doc_path in files:\n",
    "            yield read_doc(root + '/' + doc_path, encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "We will begin by indexing the sample documents stored in `./lab_demo/documents`. \n",
    "\n",
    "In order to do this, we first need to make a connection to the **Elasticsearch** server. The following code will:\n",
    "\n",
    "1. Import python **Elasticsearch** library,\n",
    "1. Establish a connection to the server,\n",
    "1. Read sample documents, and\n",
    "1. Create an inverted-index structure named `INDEX_NAME`\n",
    "\n",
    "Before we index the documents, we first need to define the **configuration of Elasticsearch**. During this process, we will define basic configuration of the indexer, such as tokenizer, stemmer, lemmatizer, and also define which search algorithm Elasticsearch will use.\n",
    "\n",
    "The code below shows a simple configuration settings for this demo.\n",
    "\n",
    "The configuration tells Elasticsearch that our document 'doc' will have three fields: `filename`, `path`, and `text`. We will use the `text` field for our search queries. The field `my_analyzer` will be used to parse the `text` field, and `my_analyzer` will also be used as a search analyzer, which will parse search queries later on. The field `index:False` in the `filename` and `path` fields tells Elasticsearch that we will not index these two fields, therefore, we cannot search these two fields with queries. The detailed documentation of analyzer can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html).\n",
    "\n",
    "The `\"similarity\": \"boolean\"` in `text` field will let Elasticsearch know that we will use a boolean search algorithm to search the `text` field. The detailed documentation of the search algorithms can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html)  and [here](https://www.elastic.co/guide/en/elasticsearch/guide/master/search-in-depth.html). Read these documents carefully ahead of attempting Assignment 1.\n",
    " \n",
    "We further define `my_analyzer` in `settings`. The analyzer consists of stopword filter (`stop`) and uses `whitespace` as the tokenizer, which separates sentences into tokens based on any whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for indexing\n",
    "demo_settings = {\n",
    "  \"mappings\": {\n",
    "    \"doc\": {\n",
    "      \"properties\": {\n",
    "        \"filename\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"path\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"similarity\": \"boolean\",\n",
    "          \"analyzer\": \"my_analyzer\",\n",
    "          \"search_analyzer\": \"my_analyzer\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },    \n",
    "  \"settings\": {      \n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_analyzer\": {\n",
    "          \"filter\": [\n",
    "            \"stop\"\n",
    "          ],\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"whitespace\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next retrieve the sample documents and index them into INDEX_NAME index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index `lab-demo` deleted\n",
      "index `lab-demo` created\n",
      "indexed 1 documents\n",
      "indexed 2 documents\n",
      "indexed 3 documents\n",
      "indexed 4 documents\n",
      "indexed 5 documents\n",
      "indexed 5 docs to index `lab-demo`, failed to index 0 docs\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "ES_HOSTS = ['http://localhost:9200']\n",
    "INDEX_NAME = 'lab-demo'\n",
    "DOCS_PATH = 'lab-demo/documents'\n",
    "DOC_TYPE = 'doc'\n",
    "\n",
    "def create_index(es_conn, index_name, settings):\n",
    "    '''\n",
    "        create index structure in elasticsearch server. \n",
    "        If index_name exists in the server, it will be removed, and new index will be created.\n",
    "        input:\n",
    "            - es_conn: elasticsearch connection object\n",
    "            - index_name: name of index to create\n",
    "            - settings: settings and mappings for index to create\n",
    "        output: =>\n",
    "            - None\n",
    "    '''\n",
    "    if es_conn.indices.exists(index_name):\n",
    "        es_conn.indices.delete(index = index_name)\n",
    "        print('index `{}` deleted'.format(index_name))\n",
    "    es_conn.indices.create(index = index_name, ignore = 400, body = settings)\n",
    "    print('index `{}` created'.format(index_name))            \n",
    "            \n",
    "def build_index(es_conn, dataset, index_name, settings, DOC_TYPE='doc'):\n",
    "    '''\n",
    "        build index from a collection of documents\n",
    "        input:\n",
    "            - es_conn: elasticsearch connection object\n",
    "            - dataset: iterable, collection of namedtuple Doc objects\n",
    "            - index_name: name of the index where the documents will be stored\n",
    "            - DOC_TYPE: type signature of documents\n",
    "    '''\n",
    "    # create the index if it doesn't exist\n",
    "    create_index(es_conn = es_conn, index_name = index_name, settings=settings)\n",
    "    counter_read, counter_idx_failed = 0, 0 # counters\n",
    "\n",
    "    # retrive & index documents\n",
    "    for doc in dataset:\n",
    "        res = es_conn.index(\n",
    "            index = index_name,\n",
    "            id = doc.filename,\n",
    "            doc_type = DOC_TYPE,\n",
    "            body = doc._asdict())\n",
    "        counter_read += 1\n",
    "\n",
    "        if res['result'] != 'created':\n",
    "            conter_idx_failed += 1\n",
    "        else:\n",
    "            print('indexed {} documents'.format(counter_read))\n",
    "\n",
    "    print('indexed {} docs to index `{}`, failed to index {} docs'.format(\n",
    "        counter_read,\n",
    "        index_name,\n",
    "        counter_idx_failed\n",
    "    ))\n",
    "    \n",
    "    # refresh after indexing\n",
    "    es_conn.indices.refresh(index=index_name)  \n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "dataset = read_dataset(DOCS_PATH)\n",
    "build_index(es_conn, dataset, INDEX_NAME, demo_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully created an inverted index for the sample documents in ./lab_demo/documents, it's time to search the documents with some queries.\n",
    "\n",
    "### Searching\n",
    "\n",
    "Elasticsearch supports a specific query grammar: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html\n",
    "\n",
    "To understand the **score** of each result, see: https://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-intro.html#explain\n",
    "\n",
    "**Example 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama, doc2.txt, 1.0\n",
      "Obama, doc5.txt, 1.0\n",
      "Obama, doc1.txt, 1.0\n",
      "Obama, doc3.txt, 1.0\n"
     ]
    }
   ],
   "source": [
    "def extract_response(res):\n",
    "    if res is not None:\n",
    "        for hit in res['hits']['hits']:\n",
    "            filename = hit[\"_source\"][\"filename\"]\n",
    "            score = hit[\"_score\"]\n",
    "            yield (filename, score)\n",
    "\n",
    "def print_result(query, res):\n",
    "    # formatter of searched result\n",
    "    matches = extract_response(res)\n",
    "    if matches is not None:\n",
    "        for match in sorted(matches, key = lambda x: -x[1]):\n",
    "            print('{}, {}, {}'.format(\n",
    "                query,\n",
    "                match[0], # filename\n",
    "                match[1], # score\n",
    "            ))\n",
    "\n",
    "# Elasticsearch Query grammar can be found here:\n",
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html\n",
    "\n",
    "# Boolean Query \"Obama\"\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\n",
    "                  \"match\": {\"text\": \"Obama\"}\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama AND Hillary, doc1.txt, 2.0\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama AND Hillary\"\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"match\" : {\n",
    "              \"text\" : {\n",
    "                \"query\" : \"Obama Hillary\",\n",
    "                \"operator\" : \"and\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama AND Hillary\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama BUT Hillary, doc2.txt, 1.0\n",
      "Obama BUT Hillary, doc5.txt, 1.0\n",
      "Obama BUT Hillary, doc3.txt, 1.0\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama BUT Hillary\"\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"must\": [\n",
    "                {\n",
    "                    \"match\": {\"text\": \"Obama\"}\n",
    "                }\n",
    "              ],\n",
    "              \"must_not\":[\n",
    "                {\n",
    "                    \"match\": {\"text\": \"Hillary\"}\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama BUT Hillary\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama OR Hillary, doc1.txt, 2.0\n",
      "Obama OR Hillary, doc4.txt, 1.0\n",
      "Obama OR Hillary, doc2.txt, 1.0\n",
      "Obama OR Hillary, doc5.txt, 1.0\n",
      "Obama OR Hillary, doc3.txt, 1.0\n"
     ]
    }
   ],
   "source": [
    "# Boolean Query \"Obama OR Hillary\"\n",
    "# default is OR\n",
    "res = es_conn.search(index = INDEX_NAME,\n",
    "    body={\n",
    "          \"query\": {\n",
    "            \"match\" : {\n",
    "              \"text\" : {\n",
    "                \"query\" : \"Obama Hillary\",\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    )\n",
    "print_result(\"Obama OR Hillary\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2: Evaluation an IR system using trec_eval\n",
    "\n",
    "In this next tutorial, now we will show how the retrieved results can be evaluated using the **trec_eval** evaluation program, which is standard software for evaluating search engines against test collections.\n",
    "\n",
    "### Initial setup\n",
    "\n",
    "First, we need to install `trec_eval`:\n",
    "\n",
    "- Unzip `trec_eval.zip`\n",
    "- Go to the `trec_eval` folder\n",
    "- Run the shell command `make` to create the `trec_eval` binary file. If you are working on your own machine you may need to install this command first using 'sudo apt-get install build-essential'.\n",
    "\n",
    "Next, take a look at the contents of the 'eval-demo' folder. It contains a small data set consisnting of three things:\n",
    "\n",
    "- A set of documents (11 email messages) needed to be indexed, in the *documents* directory.\n",
    "    \n",
    "- A set of queries, also called 'topics', in *topics/air.topics* file. The format of **.topic* file is \"query_id query_terms\". For example, the first line of 'air.topics' file is\n",
    "    \n",
    "    `01 ducks`\n",
    "    \n",
    "    which means that the ID of query is *01* and the corresponding query is *ducks*.\n",
    "\n",
    "- A set of judgements, saying which documents are relevant for each query, in the *qrels/air.qrels* file. The format of **.qrels* file is \"query_id 0 document_name binary_relevance\". For example, the first line of 'air.qrels' is\n",
    "    \n",
    "    `01 0 email01 0`\n",
    "    \n",
    "    which means that the document 'email01' is not relevant to the given query id *01*. The binary relevance is *1* \n",
    "    if the file is relevant to the query, otherwise *0*. Please ignore the second argument *0* as it is always *0*.\n",
    "    \n",
    "### Create an index\n",
    "\n",
    "In the first tutorial, we created an index (inverted-index) of five sample documents. \n",
    "\n",
    "In this tutorial, we will create a new index with the documents stored in the eval-demo/documents folder.\n",
    "\n",
    "We first need to create a new index. Note that EVAL_INDEX_NAME should be changed in order to build a separate index for the documents in eval-demo/documents.\n",
    "\n",
    "After creating the new configuration file, *your job will be to import the file, and create index using the code in the demo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for indexing\n",
    "new_settings = {\n",
    "  \"mappings\": {\n",
    "    \"doc\": {\n",
    "      \"properties\": {\n",
    "        \"filename\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"path\": {\n",
    "          \"type\": \"keyword\",\n",
    "          \"index\": False,\n",
    "        },\n",
    "        \"text\": {\n",
    "          \"type\": \"text\",\n",
    "          \"similarity\": \"boolean\",\n",
    "          \"analyzer\": \"my_analyzer\",\n",
    "          \"search_analyzer\": \"my_analyzer\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },    \n",
    "  \"settings\": {      \n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_analyzer\": {\n",
    "          \"filter\": [\n",
    "            \"stop\"\n",
    "          ],\n",
    "          \"char_filter\": [\n",
    "            \"html_strip\"\n",
    "          ],\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"whitespace\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index `eval-demo` deleted\n",
      "index `eval-demo` created\n",
      "indexed 1 documents\n",
      "indexed 2 documents\n",
      "indexed 3 documents\n",
      "indexed 4 documents\n",
      "indexed 5 documents\n",
      "indexed 6 documents\n",
      "indexed 7 documents\n",
      "indexed 8 documents\n",
      "indexed 9 documents\n",
      "indexed 10 documents\n",
      "indexed 11 documents\n",
      "indexed 11 docs to index `eval-demo`, failed to index 0 docs\n"
     ]
    }
   ],
   "source": [
    "ES_HOSTS = ['http://localhost:9200']\n",
    "EVAL_INDEX_NAME = 'eval-demo'\n",
    "EVAL_DOCS_PATH = 'eval-demo/documents'\n",
    "DOC_TYPE = 'doc'\n",
    "\n",
    "es_conn = Elasticsearch(ES_HOSTS)\n",
    "dataset = read_dataset(EVAL_DOCS_PATH)\n",
    "build_index(es_conn, dataset, EVAL_INDEX_NAME, new_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read topics and produce a results file\n",
    "\n",
    "We next need to read topics (queries) from a file (*eval-demo/topics/air.topics*) instead of having them in the program directly, as we had in Tutorial 1, where they were hard-coded. \n",
    "\n",
    "We will search the documents indexed by **Elasticsearch**. You may choose one of search algorithms used in the demo.\n",
    "\n",
    "Then, we produce a result file (e.g., *retrieved.txt*), according to the **trec_eval** standard output format: \n",
    "\n",
    "`01 Q0 email09 0 1.23 my_IR_system1`\n",
    "\n",
    "`01 Q0 email06 1 1.08 my_IR_system1`\n",
    "\n",
    "where '01' is the query ID (01 to 06); ignore 'Q0'; 'emailxx' is the name of the file; '0' (or '1' or some other integer number) is the rank of this result; '1.23' (or '1.08' or some other number) is the score of this result; and 'my_IR_system1' is the name for your retrieval system. \n",
    "\n",
    "In particular, note that the rank field will be ignored in **trec_eval**; internally ranks are assigned by sorting by the score field with ties broken deterministicly (using file name).\n",
    "\n",
    "**Now, here's your first job**\n",
    "1. Read `air.topics` file line by line, \n",
    "2. Send query to the elastic search\n",
    "3. Write output according the the output format described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 ducks\n",
      "\n",
      "02 ig nobel prizes\n",
      "\n",
      "03 mathematics\n",
      "\n",
      "04 flowing hair\n",
      "\n",
      "05 music\n",
      "\n",
      "06 AIR TV\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def search(query_string, es_conn, index_name):\n",
    "    '''\n",
    "        searches for query_string with default search algorithm\n",
    "        input:\n",
    "            - query_string: a query\n",
    "            - es_conn: elasticsearch connection\n",
    "            - index_name: name of index\n",
    "        output:\n",
    "            - a generator of tuple (filename, score)\n",
    "\n",
    "    '''\n",
    "    res = es_conn.search(index = index_name,\n",
    "        body = {\n",
    "            \"_source\": [ \"filename\"],\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"text\": {\n",
    "                        \"query\": query_string,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    for hit in res['hits']['hits']:\n",
    "        filename = hit[\"_source\"][\"filename\"]\n",
    "        score = hit[\"_score\"]\n",
    "        yield (filename, score)\n",
    "        \n",
    "\n",
    "#TODO: 1) read `air.topics` file line by line, \n",
    "#      2) send query to the elastic search\n",
    "#      3) write output according the the output format described above\n",
    "\n",
    "with open('eval-demo/topics/air.topics', 'r') as f: # Note that the 'r' means we want to read a string from this path.\n",
    "    query_strings = f.readlines()\n",
    "\n",
    "with open('retrieved.txt', 'w') as f:\n",
    "    for query_string in query_strings:\n",
    "        print(query_string)\n",
    "        matches = search(query_string[2:], es_conn, EVAL_INDEX_NAME)\n",
    "        if matches is not None:\n",
    "            for match in sorted(matches, key = lambda x: -x[1]):\n",
    "                #print(match)\n",
    "                f.write('{} Q0 {} 0 {} my_IR_system1\\n'.format(\n",
    "                    query_string.split(' ')[0],\n",
    "                    match[0], # filename\n",
    "                    match[1], # score\n",
    "        ))\n",
    "        #print('query done')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "\n",
    "Once you have done this, index and rank the documents for any or all of the six test queries, and run **trec_eval** which compares the qrels file provided in *air.qrels* with your results file. (hint: adding a **!** and shell commands allow you to execute shell commands in jupyter-notebook, e.g. `!ls`)\n",
    "\n",
    "TREC_EVAL will evaluate the performance of your search engine. \n",
    "\n",
    "To evaluate your search result, you first need two sets of files: the retrieved result file and the ground truth file. Let's say your retrieval result is saved as `retrieved.txt`, and the ground truth file is saved as `air.qrels`, then the performance of your retrieval can be measured via:\n",
    "\n",
    "`./trec_eval/trec_eval  air.qrels retrieved.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\tmy_IR_system1\r\n",
      "num_q                 \tall\t4\r\n",
      "num_ret               \tall\t13\r\n",
      "num_rel               \tall\t12\r\n",
      "num_rel_ret           \tall\t4\r\n",
      "map                   \tall\t0.2792\r\n",
      "gm_map                \tall\t0.0250\r\n",
      "Rprec                 \tall\t0.2583\r\n",
      "bpref                 \tall\t0.3833\r\n",
      "recip_rank            \tall\t0.6250\r\n",
      "iprec_at_recall_0.00  \tall\t0.6667\r\n",
      "iprec_at_recall_0.10  \tall\t0.6667\r\n",
      "iprec_at_recall_0.20  \tall\t0.6667\r\n",
      "iprec_at_recall_0.30  \tall\t0.4167\r\n",
      "iprec_at_recall_0.40  \tall\t0.1667\r\n",
      "iprec_at_recall_0.50  \tall\t0.1667\r\n",
      "iprec_at_recall_0.60  \tall\t0.1667\r\n",
      "iprec_at_recall_0.70  \tall\t0.1667\r\n",
      "iprec_at_recall_0.80  \tall\t0.1667\r\n",
      "iprec_at_recall_0.90  \tall\t0.1667\r\n",
      "iprec_at_recall_1.00  \tall\t0.1667\r\n",
      "P_5                   \tall\t0.2000\r\n",
      "P_10                  \tall\t0.1000\r\n",
      "P_15                  \tall\t0.0667\r\n",
      "P_20                  \tall\t0.0500\r\n",
      "P_30                  \tall\t0.0333\r\n",
      "P_100                 \tall\t0.0100\r\n",
      "P_200                 \tall\t0.0050\r\n",
      "P_500                 \tall\t0.0020\r\n",
      "P_1000                \tall\t0.0010\r\n"
     ]
    }
   ],
   "source": [
    "# your shell command for comparing *air.qrels* against *retrieved.txt*\n",
    "!./trec_eval/trec_eval ./eval-demo/qrels/air.qrels retrieved.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If **trec_eval** runs correctly and produces numbers which you think are sensible, then you have completed this tutorial!\n",
    "\n",
    "You may want to look at the output, though, and get some understanding of what it means. **In Assignment 1, you will be asked to interpret this and to choose evaluation measures you prefer.**\n",
    "\n",
    "Running `./trec_eval/trec_eval -h` will list all the options available.\n",
    "\n",
    "**TODO**: \n",
    "- Try to change the configuration of elastic search (`new_settings`), \n",
    "- Modify `search` using different DSL query structure, and \n",
    "- Compare result with the above example via `trec_eval`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing analyzers\n",
    "We used dictionary structured settings when we created the indexes. \n",
    "\n",
    "However, there are multiple ways to change the configuration of settings. Please refer to the official elastic search pages [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html) for more details. Try different filters and tokenizers by changing the settings.\n",
    "\n",
    "Additionally, you can test your analyzer with arbitrary text using the `analyze_query` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b\"Let's\", b'see.', b'how', b'analyzer', b'analyse.', b'sentence.!']\n"
     ]
    }
   ],
   "source": [
    "def analyze_query(text, es_conn, index_name):\n",
    "    '''\n",
    "        analyzes any text with my_analyzer defined in es_settings.json\n",
    "        input:\n",
    "            - text: a query text\n",
    "            - es_conn: elasticsearch connection\n",
    "            - index_name: name of index\n",
    "        output:\n",
    "            - a list of tokens\n",
    "    '''\n",
    "\n",
    "    tokens = es_conn.indices.analyze(\n",
    "        index = index_name,\n",
    "        body = {\"text\": text, \"analyzer\": \"my_analyzer\"})['tokens']\n",
    "\n",
    "    return [token_row[\"token\"].encode('utf-8') for token_row in tokens]\n",
    "\n",
    "print(analyze_query(\"Let's see. how the analyzer analyse. this sentence.!\", es_conn, INDEX_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You are ready to solve the first assignment! Open Assignment1.ipynb for further instructions.\n",
    "\n",
    "### Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
